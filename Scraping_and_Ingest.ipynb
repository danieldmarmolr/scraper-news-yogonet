{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bjE30SB61n2w",
    "outputId": "b124d1f4-eb68-4bd8-d445-08432e3afae1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting selenium\n",
      "  Downloading selenium-4.29.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\56937\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (1.4.1)\n",
      "Requirement already satisfied: google-cloud-bigquery in c:\\users\\56937\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (3.30.0)\n",
      "Requirement already satisfied: google-auth in c:\\users\\56937\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (2.38.0)\n",
      "Requirement already satisfied: textblob in c:\\users\\56937\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.19.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in c:\\users\\56937\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (2.3.0)\n",
      "Collecting trio~=0.17 (from selenium)\n",
      "  Downloading trio-0.29.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting trio-websocket~=0.9 (from selenium)\n",
      "  Downloading trio_websocket-0.12.2-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\56937\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from selenium) (2025.1.31)\n",
      "Collecting typing_extensions~=4.9 (from selenium)\n",
      "  Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting websocket-client~=1.8 (from selenium)\n",
      "  Downloading websocket_client-1.8.0-py3-none-any.whl.metadata (8.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\56937\\appdata\\roaming\\python\\python39\\site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\56937\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\56937\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas) (1.20.2)\n",
      "Requirement already satisfied: google-api-core<3.0.0dev,>=2.11.1 in c:\\users\\56937\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-api-core[grpc]<3.0.0dev,>=2.11.1->google-cloud-bigquery) (2.24.1)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0dev,>=2.4.1 in c:\\users\\56937\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-cloud-bigquery) (2.4.2)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=2.0.0 in c:\\users\\56937\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-cloud-bigquery) (2.7.2)\n",
      "Requirement already satisfied: packaging>=20.0.0 in c:\\users\\56937\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-cloud-bigquery) (24.2)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.21.0 in c:\\users\\56937\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-cloud-bigquery) (2.32.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\56937\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-auth) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\56937\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-auth) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\56937\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-auth) (4.9)\n",
      "Requirement already satisfied: nltk>=3.9 in c:\\users\\56937\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from textblob) (3.9.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in c:\\users\\56937\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-api-core<3.0.0dev,>=2.11.1->google-api-core[grpc]<3.0.0dev,>=2.11.1->google-cloud-bigquery) (1.69.1)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.19.5 in c:\\users\\56937\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-api-core<3.0.0dev,>=2.11.1->google-api-core[grpc]<3.0.0dev,>=2.11.1->google-cloud-bigquery) (5.29.3)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\56937\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-api-core<3.0.0dev,>=2.11.1->google-api-core[grpc]<3.0.0dev,>=2.11.1->google-cloud-bigquery) (1.26.0)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\users\\56937\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-api-core[grpc]<3.0.0dev,>=2.11.1->google-cloud-bigquery) (1.70.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in c:\\users\\56937\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-api-core[grpc]<3.0.0dev,>=2.11.1->google-cloud-bigquery) (1.70.0)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in c:\\users\\56937\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-resumable-media<3.0dev,>=2.0.0->google-cloud-bigquery) (1.6.0)\n",
      "Requirement already satisfied: click in c:\\users\\56937\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nltk>=3.9->textblob) (8.1.8)\n",
      "Requirement already satisfied: joblib in c:\\users\\56937\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nltk>=3.9->textblob) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\56937\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nltk>=3.9->textblob) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\56937\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nltk>=3.9->textblob) (4.67.1)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\users\\56937\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth) (0.6.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\56937\\appdata\\roaming\\python\\python39\\site-packages (from python-dateutil>=2.8.1->pandas) (1.15.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\56937\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3.0.0dev,>=2.21.0->google-cloud-bigquery) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\56937\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3.0.0dev,>=2.21.0->google-cloud-bigquery) (3.10)\n",
      "Collecting attrs>=23.2.0 (from trio~=0.17->selenium)\n",
      "  Downloading attrs-25.1.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting sortedcontainers (from trio~=0.17->selenium)\n",
      "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting outcome (from trio~=0.17->selenium)\n",
      "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting sniffio>=1.3.0 (from trio~=0.17->selenium)\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting cffi>=1.14 (from trio~=0.17->selenium)\n",
      "  Downloading cffi-1.17.1-cp39-cp39-win_amd64.whl.metadata (1.6 kB)\n",
      "Collecting exceptiongroup (from trio~=0.17->selenium)\n",
      "  Downloading exceptiongroup-1.2.2-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium)\n",
      "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting pysocks!=1.5.7,<2.0,>=1.5.6 (from urllib3[socks]<3,>=1.26->selenium)\n",
      "  Downloading PySocks-1.7.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting pycparser (from cffi>=1.14->trio~=0.17->selenium)\n",
      "  Downloading pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
      "Collecting h11<1,>=0.9.0 (from wsproto>=0.14->trio-websocket~=0.9->selenium)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\56937\\appdata\\roaming\\python\\python39\\site-packages (from click->nltk>=3.9->textblob) (0.4.4)\n",
      "Downloading selenium-4.29.0-py3-none-any.whl (9.5 MB)\n",
      "   ---------------------------------------- 9.5/9.5 MB 8.4 MB/s eta 0:00:00\n",
      "Downloading trio-0.29.0-py3-none-any.whl (492 kB)\n",
      "Downloading trio_websocket-0.12.2-py3-none-any.whl (21 kB)\n",
      "Downloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Downloading websocket_client-1.8.0-py3-none-any.whl (58 kB)\n",
      "Downloading attrs-25.1.0-py3-none-any.whl (63 kB)\n",
      "Downloading cffi-1.17.1-cp39-cp39-win_amd64.whl (181 kB)\n",
      "Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
      "Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Downloading exceptiongroup-1.2.2-py3-none-any.whl (16 kB)\n",
      "Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Downloading pycparser-2.22-py3-none-any.whl (117 kB)\n",
      "Installing collected packages: sortedcontainers, websocket-client, typing_extensions, sniffio, pysocks, pycparser, h11, exceptiongroup, attrs, wsproto, outcome, cffi, trio, trio-websocket, selenium\n",
      "Successfully installed attrs-25.1.0 cffi-1.17.1 exceptiongroup-1.2.2 h11-0.14.0 outcome-1.3.0.post0 pycparser-2.22 pysocks-1.7.1 selenium-4.29.0 sniffio-1.3.1 sortedcontainers-2.4.0 trio-0.29.0 trio-websocket-0.12.2 typing_extensions-4.12.2 websocket-client-1.8.0 wsproto-1.2.0\n",
      "Requirement already satisfied: selenium in c:\\users\\56937\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (4.29.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\56937\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (1.4.1)\n",
      "Collecting webdriver-manager\n",
      "  Downloading webdriver_manager-4.0.2-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in c:\\users\\56937\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (2.3.0)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\56937\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from selenium) (0.29.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\56937\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from selenium) (0.12.2)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\56937\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from selenium) (2025.1.31)\n",
      "Requirement already satisfied: typing_extensions~=4.9 in c:\\users\\56937\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from selenium) (4.12.2)\n",
      "Requirement already satisfied: websocket-client~=1.8 in c:\\users\\56937\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from selenium) (1.8.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\56937\\appdata\\roaming\\python\\python39\\site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\56937\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\56937\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas) (1.20.2)\n",
      "Requirement already satisfied: requests in c:\\users\\56937\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from webdriver-manager) (2.32.3)\n",
      "Collecting python-dotenv (from webdriver-manager)\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\56937\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from webdriver-manager) (24.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\56937\\appdata\\roaming\\python\\python39\\site-packages (from python-dateutil>=2.8.1->pandas) (1.15.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in c:\\users\\56937\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from trio~=0.17->selenium) (25.1.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\56937\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\56937\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from trio~=0.17->selenium) (3.10)\n",
      "Requirement already satisfied: outcome in c:\\users\\56937\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\56937\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from trio~=0.17->selenium) (1.3.1)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\56937\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from trio~=0.17->selenium) (1.17.1)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\56937\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from trio~=0.17->selenium) (1.2.2)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\56937\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\56937\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\56937\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->webdriver-manager) (3.4.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\56937\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.22)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\56937\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Downloading webdriver_manager-4.0.2-py2.py3-none-any.whl (27 kB)\n",
      "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: python-dotenv, webdriver-manager\n",
      "Successfully installed python-dotenv-1.0.1 webdriver-manager-4.0.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install selenium pandas webdriver-manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 597
    },
    "id": "kAEfvd49mhWa",
    "outputId": "2d47b0e0-65ef-42d4-f31c-1f4b99cd4d34"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Title</th>\n",
       "      <th>Kicker</th>\n",
       "      <th>Image</th>\n",
       "      <th>Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-03-07</td>\n",
       "      <td>GOLDSTEIN TO BECOME SENIOR ADVISER</td>\n",
       "      <td>Las Vegas Sands CEO Robert Goldstein to step d...</td>\n",
       "      <td>https://imagenesyogonet.b-cdn.net/data/imagene...</td>\n",
       "      <td>https://www.yogonet.com/international/news/202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-03-07</td>\n",
       "      <td>HAS OVER 250 ROOMS</td>\n",
       "      <td>Michigan’s Gun Lake Casino opens new 16-story ...</td>\n",
       "      <td>https://imagenesyogonet.b-cdn.net/data/imagene...</td>\n",
       "      <td>https://www.yogonet.com/international/news/202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-03-07</td>\n",
       "      <td>TO DRIVE GROWTH, ENHANCE GUEST EXPERIENCE</td>\n",
       "      <td>Virgin Las Vegas appoints former Venetian exec...</td>\n",
       "      <td>https://imagenesyogonet.b-cdn.net/data/imagene...</td>\n",
       "      <td>https://www.yogonet.com/international/news/202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-03-07</td>\n",
       "      <td>EBITDA DROPS SHARPLY TO $1 MILLION</td>\n",
       "      <td>Resorts World Las Vegas reports weak Q4 2024 e...</td>\n",
       "      <td>https://imagenesyogonet.b-cdn.net/data/imagene...</td>\n",
       "      <td>https://www.yogonet.com/international/news/202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-03-06</td>\n",
       "      <td>EXCEEDS GOVERNMENT PROJECTIONS BY 5.4%</td>\n",
       "      <td>Macau’s gaming tax revenue up 35% to $11 billi...</td>\n",
       "      <td>https://imagenesyogonet.b-cdn.net/data/imagene...</td>\n",
       "      <td>https://www.yogonet.com/international/news/202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>2024-10-08</td>\n",
       "      <td>ITS 11TH STATE IN THE US</td>\n",
       "      <td>Lotto.com enters Massachusetts, bringing first...</td>\n",
       "      <td>https://imagenesyogonet.b-cdn.net/data/imagene...</td>\n",
       "      <td>https://www.yogonet.com/international/news/202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>2024-09-30</td>\n",
       "      <td>SUSTAINABLE PRACTICES ADOPTED</td>\n",
       "      <td>The European Lotteries announces Greenhouse Ga...</td>\n",
       "      <td>https://imagenesyogonet.b-cdn.net/data/imagene...</td>\n",
       "      <td>https://www.yogonet.com/international/news/202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>2024-09-30</td>\n",
       "      <td>EIGHT ADDITIONAL CATEGORIES</td>\n",
       "      <td>Texas Lottery wins two awards at NASPL Conference</td>\n",
       "      <td>https://imagenesyogonet.b-cdn.net/data/imagene...</td>\n",
       "      <td>https://www.yogonet.com/international/news/202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>2024-09-27</td>\n",
       "      <td>AIMS TO ENHANCE PLAYER ENGAGEMENT</td>\n",
       "      <td>Florida Lottery unveils four new scratch-off g...</td>\n",
       "      <td>https://imagenesyogonet.b-cdn.net/data/imagene...</td>\n",
       "      <td>https://www.yogonet.com/international/news/202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>2024-09-16</td>\n",
       "      <td>OLG INCREASED TOP LIMIT THIS MONTH</td>\n",
       "      <td>Canada reaches record limit of $59 million jac...</td>\n",
       "      <td>https://imagenesyogonet.b-cdn.net/data/imagene...</td>\n",
       "      <td>https://www.yogonet.com/international/news/202...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date                                      Title  \\\n",
       "0   2025-03-07         GOLDSTEIN TO BECOME SENIOR ADVISER   \n",
       "1   2025-03-07                         HAS OVER 250 ROOMS   \n",
       "2   2025-03-07  TO DRIVE GROWTH, ENHANCE GUEST EXPERIENCE   \n",
       "3   2025-03-07         EBITDA DROPS SHARPLY TO $1 MILLION   \n",
       "4   2025-03-06     EXCEEDS GOVERNMENT PROJECTIONS BY 5.4%   \n",
       "..         ...                                        ...   \n",
       "75  2024-10-08                   ITS 11TH STATE IN THE US   \n",
       "76  2024-09-30              SUSTAINABLE PRACTICES ADOPTED   \n",
       "77  2024-09-30                EIGHT ADDITIONAL CATEGORIES   \n",
       "78  2024-09-27          AIMS TO ENHANCE PLAYER ENGAGEMENT   \n",
       "79  2024-09-16         OLG INCREASED TOP LIMIT THIS MONTH   \n",
       "\n",
       "                                               Kicker  \\\n",
       "0   Las Vegas Sands CEO Robert Goldstein to step d...   \n",
       "1   Michigan’s Gun Lake Casino opens new 16-story ...   \n",
       "2   Virgin Las Vegas appoints former Venetian exec...   \n",
       "3   Resorts World Las Vegas reports weak Q4 2024 e...   \n",
       "4   Macau’s gaming tax revenue up 35% to $11 billi...   \n",
       "..                                                ...   \n",
       "75  Lotto.com enters Massachusetts, bringing first...   \n",
       "76  The European Lotteries announces Greenhouse Ga...   \n",
       "77  Texas Lottery wins two awards at NASPL Conference   \n",
       "78  Florida Lottery unveils four new scratch-off g...   \n",
       "79  Canada reaches record limit of $59 million jac...   \n",
       "\n",
       "                                                Image  \\\n",
       "0   https://imagenesyogonet.b-cdn.net/data/imagene...   \n",
       "1   https://imagenesyogonet.b-cdn.net/data/imagene...   \n",
       "2   https://imagenesyogonet.b-cdn.net/data/imagene...   \n",
       "3   https://imagenesyogonet.b-cdn.net/data/imagene...   \n",
       "4   https://imagenesyogonet.b-cdn.net/data/imagene...   \n",
       "..                                                ...   \n",
       "75  https://imagenesyogonet.b-cdn.net/data/imagene...   \n",
       "76  https://imagenesyogonet.b-cdn.net/data/imagene...   \n",
       "77  https://imagenesyogonet.b-cdn.net/data/imagene...   \n",
       "78  https://imagenesyogonet.b-cdn.net/data/imagene...   \n",
       "79  https://imagenesyogonet.b-cdn.net/data/imagene...   \n",
       "\n",
       "                                                 Link  \n",
       "0   https://www.yogonet.com/international/news/202...  \n",
       "1   https://www.yogonet.com/international/news/202...  \n",
       "2   https://www.yogonet.com/international/news/202...  \n",
       "3   https://www.yogonet.com/international/news/202...  \n",
       "4   https://www.yogonet.com/international/news/202...  \n",
       "..                                                ...  \n",
       "75  https://www.yogonet.com/international/news/202...  \n",
       "76  https://www.yogonet.com/international/news/202...  \n",
       "77  https://www.yogonet.com/international/news/202...  \n",
       "78  https://www.yogonet.com/international/news/202...  \n",
       "79  https://www.yogonet.com/international/news/202...  \n",
       "\n",
       "[80 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import pandas as pd\n",
    "\n",
    "def remove_date(text):\n",
    "    \"\"\"Remove date from the Title text.\"\"\"\n",
    "    return ' '.join(text.split()[1:])\n",
    "\n",
    "def extract_news_details(base_url, max_pages):\n",
    "    \"\"\"Extract news details from the given base URL up to the specified number of pages.\"\"\"\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument('--headless')\n",
    "    options.add_argument('--no-sandbox')\n",
    "    options.add_argument('--disable-dev-shm-usage')\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "\n",
    "    page_url = base_url\n",
    "\n",
    "    # Initialize lists to store the details\n",
    "    titles = []\n",
    "    kickers = []\n",
    "    images = []\n",
    "    links = []\n",
    "    dates = []\n",
    "\n",
    "    # Initialize page counter\n",
    "    page_counter = 0\n",
    "\n",
    "    while page_counter < max_pages:\n",
    "        # Open the URL\n",
    "        driver.get(page_url)\n",
    "\n",
    "        # Select all div elements with the class \"item_noticias\"\n",
    "        items = driver.find_elements(By.CLASS_NAME, 'item_noticias')\n",
    "\n",
    "        # Iterate over each element and extract the necessary details\n",
    "        for item in items:\n",
    "            title = item.find_element(By.CLASS_NAME, 'fuente_roboto_slab').text\n",
    "            kicker = item.find_element(By.TAG_NAME, 'a').get_attribute('title')\n",
    "            image = item.find_element(By.TAG_NAME, 'img').get_attribute('src')\n",
    "            link = item.find_element(By.TAG_NAME, 'a').get_attribute('href')\n",
    "            date = item.find_element(By.CLASS_NAME, 'fecha_item_listado_noticias').text\n",
    "\n",
    "            titles.append(title)\n",
    "            kickers.append(kicker)\n",
    "            images.append(image)\n",
    "            links.append(link)\n",
    "            dates.append(date)\n",
    "\n",
    "        # Check if there is a \"Next\" button to go to the next page\n",
    "        try:\n",
    "            next_button = driver.find_element(By.CLASS_NAME, 'boton_paginador siguiente')\n",
    "            page_number = int(page_url.split('=')[-1]) if '=' in page_url else 1\n",
    "            page_url = f\"{base_url}?buscar=&pagina={page_number + 1}\"\n",
    "            page_counter += 1\n",
    "        except:\n",
    "            break\n",
    "\n",
    "    # Close the WebDriver\n",
    "    driver.quit()\n",
    "\n",
    "    # Create a DataFrame to store the details\n",
    "    data = {\n",
    "        'Date': dates,\n",
    "        'Title': titles,\n",
    "        'Kicker': kickers,\n",
    "        'Image': images,\n",
    "        'Link': links\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Apply the remove_date function to the 'Title' column\n",
    "    df['Title'] = df['Title'].apply(remove_date)\n",
    "\n",
    "    return df\n",
    "\n",
    "def get_category_links():\n",
    "    \"\"\"Get category links from the main page.\"\"\"\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument('--headless')\n",
    "    options.add_argument('--no-sandbox')\n",
    "    options.add_argument('--disable-dev-shm-usage')\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "\n",
    "    url = \"https://www.yogonet.com/international/\"\n",
    "\n",
    "    # Open the URL\n",
    "    driver.get(url)\n",
    "\n",
    "    # Move cursor over the \"Categories\" tab\n",
    "    categories_tab = driver.find_element(By.CSS_SELECTOR, '.item_menu.transition_02.tiene_hijos.categorias')\n",
    "    ActionChains(driver).move_to_element(categories_tab).perform()\n",
    "\n",
    "    # Select all elements with the class \"item_menu hijo\"\n",
    "    items = driver.find_elements(By.CSS_SELECTOR, '.contenedor_items_hijos .item_menu.hijo')\n",
    "\n",
    "    # Initialize list to store the links\n",
    "    links = []\n",
    "\n",
    "    # Iterate over each element and extract the necessary details\n",
    "    for item in items:\n",
    "        link = item.find_element(By.CSS_SELECTOR, 'a').get_attribute('href')\n",
    "        links.append(link)\n",
    "\n",
    "    # Close the WebDriver\n",
    "    driver.quit()\n",
    "\n",
    "    # Create a DataFrame to store the details\n",
    "    data = {\n",
    "        'Link': links\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Convert the 'Link' column to a list of URLs\n",
    "    urls = df['Link'].tolist()\n",
    "\n",
    "    return urls[:4]\n",
    "\n",
    "# Call the function and display the list of URLs\n",
    "urls = get_category_links()\n",
    "\n",
    "# Initialize an empty DataFrame to store combined results\n",
    "combined_df = pd.DataFrame()\n",
    "\n",
    "for url in urls:\n",
    "    df = extract_news_details(url, max_pages=1)\n",
    "    combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
    "\n",
    "# Display the combined DataFrame\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "qGt3j9N4QRqQ",
    "outputId": "09d69f84-c723-4e26-b42c-4e188b8df5ba"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Title</th>\n",
       "      <th>Kicker</th>\n",
       "      <th>Image</th>\n",
       "      <th>Link</th>\n",
       "      <th>Word_Count_Title</th>\n",
       "      <th>Word_Count_Kicker</th>\n",
       "      <th>Character_Count_Title</th>\n",
       "      <th>Character_Count_Kicker</th>\n",
       "      <th>Capital_Words_Kicker</th>\n",
       "      <th>Sentiment_Title</th>\n",
       "      <th>Sentiment_Kicker</th>\n",
       "      <th>Keyword_Frequency_Title</th>\n",
       "      <th>Keyword_Frequency_Kicker</th>\n",
       "      <th>Readability_Score_Title</th>\n",
       "      <th>Readability_Score_Kicker</th>\n",
       "      <th>Title_Complexity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-03-07</td>\n",
       "      <td>GOLDSTEIN TO BECOME SENIOR ADVISER</td>\n",
       "      <td>Las Vegas Sands CEO Robert Goldstein to step d...</td>\n",
       "      <td>https://imagenesyogonet.b-cdn.net/data/imagene...</td>\n",
       "      <td>https://www.yogonet.com/international/news/202...</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>34</td>\n",
       "      <td>84</td>\n",
       "      <td>[Las, Vegas, Sands, Robert, Goldstein, Patrick...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.155556</td>\n",
       "      <td>{'to': 1, 'for': 0, 'in': 0, 'million': 0, 'up...</td>\n",
       "      <td>{'to': 2, 'for': 0, 'in': 1, 'million': 0, 'up...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-03-07</td>\n",
       "      <td>HAS OVER 250 ROOMS</td>\n",
       "      <td>Michigan’s Gun Lake Casino opens new 16-story ...</td>\n",
       "      <td>https://imagenesyogonet.b-cdn.net/data/imagene...</td>\n",
       "      <td>https://www.yogonet.com/international/news/202...</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>18</td>\n",
       "      <td>70</td>\n",
       "      <td>[Gun, Lake, Casino, $300M]</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>{'to': 0, 'for': 0, 'in': 0, 'million': 0, 'up...</td>\n",
       "      <td>{'to': 0, 'for': 0, 'in': 1, 'million': 0, 'up...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-03-07</td>\n",
       "      <td>TO DRIVE GROWTH, ENHANCE GUEST EXPERIENCE</td>\n",
       "      <td>Virgin Las Vegas appoints former Venetian exec...</td>\n",
       "      <td>https://imagenesyogonet.b-cdn.net/data/imagene...</td>\n",
       "      <td>https://www.yogonet.com/international/news/202...</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>41</td>\n",
       "      <td>101</td>\n",
       "      <td>[Virgin, Las, Vegas, Venetian, John, Fechik, S...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{'to': 1, 'for': 0, 'in': 0, 'million': 0, 'up...</td>\n",
       "      <td>{'to': 0, 'for': 0, 'in': 0, 'million': 0, 'up...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-03-07</td>\n",
       "      <td>EBITDA DROPS SHARPLY TO $1 MILLION</td>\n",
       "      <td>Resorts World Las Vegas reports weak Q4 2024 e...</td>\n",
       "      <td>https://imagenesyogonet.b-cdn.net/data/imagene...</td>\n",
       "      <td>https://www.yogonet.com/international/news/202...</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>34</td>\n",
       "      <td>84</td>\n",
       "      <td>[Resorts, World, Las, Vegas, Q4]</td>\n",
       "      <td>-0.125</td>\n",
       "      <td>-0.375000</td>\n",
       "      <td>{'to': 1, 'for': 0, 'in': 0, 'million': 1, 'up...</td>\n",
       "      <td>{'to': 1, 'for': 0, 'in': 0, 'million': 1, 'up...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>95.939286</td>\n",
       "      <td>4.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-03-06</td>\n",
       "      <td>EXCEEDS GOVERNMENT PROJECTIONS BY 5.4%</td>\n",
       "      <td>Macau’s gaming tax revenue up 35% to $11 billi...</td>\n",
       "      <td>https://imagenesyogonet.b-cdn.net/data/imagene...</td>\n",
       "      <td>https://www.yogonet.com/international/news/202...</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>38</td>\n",
       "      <td>56</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{'to': 0, 'for': 0, 'in': 0, 'million': 0, 'up...</td>\n",
       "      <td>{'to': 1, 'for': 0, 'in': 1, 'million': 0, 'up...</td>\n",
       "      <td>49.48</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>2024-10-08</td>\n",
       "      <td>ITS 11TH STATE IN THE US</td>\n",
       "      <td>Lotto.com enters Massachusetts, bringing first...</td>\n",
       "      <td>https://imagenesyogonet.b-cdn.net/data/imagene...</td>\n",
       "      <td>https://www.yogonet.com/international/news/202...</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>24</td>\n",
       "      <td>83</td>\n",
       "      <td>[Massachusetts,]</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{'to': 0, 'for': 0, 'in': 1, 'million': 0, 'up...</td>\n",
       "      <td>{'to': 0, 'for': 0, 'in': 0, 'million': 0, 'up...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-18.500000</td>\n",
       "      <td>3.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>2024-09-30</td>\n",
       "      <td>SUSTAINABLE PRACTICES ADOPTED</td>\n",
       "      <td>The European Lotteries announces Greenhouse Ga...</td>\n",
       "      <td>https://imagenesyogonet.b-cdn.net/data/imagene...</td>\n",
       "      <td>https://www.yogonet.com/international/news/202...</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>29</td>\n",
       "      <td>103</td>\n",
       "      <td>[The, European, Lotteries, Greenhouse, Gas, Em...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{'to': 0, 'for': 0, 'in': 0, 'million': 0, 'up...</td>\n",
       "      <td>{'to': 1, 'for': 0, 'in': 0, 'million': 0, 'up...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>2024-09-30</td>\n",
       "      <td>EIGHT ADDITIONAL CATEGORIES</td>\n",
       "      <td>Texas Lottery wins two awards at NASPL Conference</td>\n",
       "      <td>https://imagenesyogonet.b-cdn.net/data/imagene...</td>\n",
       "      <td>https://www.yogonet.com/international/news/202...</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>27</td>\n",
       "      <td>49</td>\n",
       "      <td>[Texas, Lottery, Conference]</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>{'to': 0, 'for': 0, 'in': 0, 'million': 0, 'up...</td>\n",
       "      <td>{'to': 0, 'for': 0, 'in': 0, 'million': 0, 'up...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>2024-09-27</td>\n",
       "      <td>AIMS TO ENHANCE PLAYER ENGAGEMENT</td>\n",
       "      <td>Florida Lottery unveils four new scratch-off g...</td>\n",
       "      <td>https://imagenesyogonet.b-cdn.net/data/imagene...</td>\n",
       "      <td>https://www.yogonet.com/international/news/202...</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>33</td>\n",
       "      <td>88</td>\n",
       "      <td>[Florida, Lottery]</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>{'to': 1, 'for': 0, 'in': 0, 'million': 0, 'up...</td>\n",
       "      <td>{'to': 0, 'for': 0, 'in': 1, 'million': 1, 'up...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>2024-09-16</td>\n",
       "      <td>OLG INCREASED TOP LIMIT THIS MONTH</td>\n",
       "      <td>Canada reaches record limit of $59 million jac...</td>\n",
       "      <td>https://imagenesyogonet.b-cdn.net/data/imagene...</td>\n",
       "      <td>https://www.yogonet.com/international/news/202...</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>34</td>\n",
       "      <td>70</td>\n",
       "      <td>[Canada, Lotto, Max]</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{'to': 0, 'for': 0, 'in': 0, 'million': 0, 'up...</td>\n",
       "      <td>{'to': 0, 'for': 1, 'in': 0, 'million': 1, 'up...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.833333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date                                      Title  \\\n",
       "0   2025-03-07         GOLDSTEIN TO BECOME SENIOR ADVISER   \n",
       "1   2025-03-07                         HAS OVER 250 ROOMS   \n",
       "2   2025-03-07  TO DRIVE GROWTH, ENHANCE GUEST EXPERIENCE   \n",
       "3   2025-03-07         EBITDA DROPS SHARPLY TO $1 MILLION   \n",
       "4   2025-03-06     EXCEEDS GOVERNMENT PROJECTIONS BY 5.4%   \n",
       "..         ...                                        ...   \n",
       "75  2024-10-08                   ITS 11TH STATE IN THE US   \n",
       "76  2024-09-30              SUSTAINABLE PRACTICES ADOPTED   \n",
       "77  2024-09-30                EIGHT ADDITIONAL CATEGORIES   \n",
       "78  2024-09-27          AIMS TO ENHANCE PLAYER ENGAGEMENT   \n",
       "79  2024-09-16         OLG INCREASED TOP LIMIT THIS MONTH   \n",
       "\n",
       "                                               Kicker  \\\n",
       "0   Las Vegas Sands CEO Robert Goldstein to step d...   \n",
       "1   Michigan’s Gun Lake Casino opens new 16-story ...   \n",
       "2   Virgin Las Vegas appoints former Venetian exec...   \n",
       "3   Resorts World Las Vegas reports weak Q4 2024 e...   \n",
       "4   Macau’s gaming tax revenue up 35% to $11 billi...   \n",
       "..                                                ...   \n",
       "75  Lotto.com enters Massachusetts, bringing first...   \n",
       "76  The European Lotteries announces Greenhouse Ga...   \n",
       "77  Texas Lottery wins two awards at NASPL Conference   \n",
       "78  Florida Lottery unveils four new scratch-off g...   \n",
       "79  Canada reaches record limit of $59 million jac...   \n",
       "\n",
       "                                                Image  \\\n",
       "0   https://imagenesyogonet.b-cdn.net/data/imagene...   \n",
       "1   https://imagenesyogonet.b-cdn.net/data/imagene...   \n",
       "2   https://imagenesyogonet.b-cdn.net/data/imagene...   \n",
       "3   https://imagenesyogonet.b-cdn.net/data/imagene...   \n",
       "4   https://imagenesyogonet.b-cdn.net/data/imagene...   \n",
       "..                                                ...   \n",
       "75  https://imagenesyogonet.b-cdn.net/data/imagene...   \n",
       "76  https://imagenesyogonet.b-cdn.net/data/imagene...   \n",
       "77  https://imagenesyogonet.b-cdn.net/data/imagene...   \n",
       "78  https://imagenesyogonet.b-cdn.net/data/imagene...   \n",
       "79  https://imagenesyogonet.b-cdn.net/data/imagene...   \n",
       "\n",
       "                                                 Link  Word_Count_Title  \\\n",
       "0   https://www.yogonet.com/international/news/202...                 5   \n",
       "1   https://www.yogonet.com/international/news/202...                 4   \n",
       "2   https://www.yogonet.com/international/news/202...                 6   \n",
       "3   https://www.yogonet.com/international/news/202...                 6   \n",
       "4   https://www.yogonet.com/international/news/202...                 5   \n",
       "..                                                ...               ...   \n",
       "75  https://www.yogonet.com/international/news/202...                 6   \n",
       "76  https://www.yogonet.com/international/news/202...                 3   \n",
       "77  https://www.yogonet.com/international/news/202...                 3   \n",
       "78  https://www.yogonet.com/international/news/202...                 5   \n",
       "79  https://www.yogonet.com/international/news/202...                 6   \n",
       "\n",
       "    Word_Count_Kicker  Character_Count_Title  Character_Count_Kicker  \\\n",
       "0                  15                     34                      84   \n",
       "1                  11                     18                      70   \n",
       "2                  15                     41                     101   \n",
       "3                  14                     34                      84   \n",
       "4                  11                     38                      56   \n",
       "..                ...                    ...                     ...   \n",
       "75                  9                     24                      83   \n",
       "76                 13                     29                     103   \n",
       "77                  8                     27                      49   \n",
       "78                 14                     33                      88   \n",
       "79                 12                     34                      70   \n",
       "\n",
       "                                 Capital_Words_Kicker  Sentiment_Title  \\\n",
       "0   [Las, Vegas, Sands, Robert, Goldstein, Patrick...            0.000   \n",
       "1                          [Gun, Lake, Casino, $300M]            0.000   \n",
       "2   [Virgin, Las, Vegas, Venetian, John, Fechik, S...            0.000   \n",
       "3                    [Resorts, World, Las, Vegas, Q4]           -0.125   \n",
       "4                                                  []            0.000   \n",
       "..                                                ...              ...   \n",
       "75                                   [Massachusetts,]            0.000   \n",
       "76  [The, European, Lotteries, Greenhouse, Gas, Em...            0.000   \n",
       "77                       [Texas, Lottery, Conference]            0.000   \n",
       "78                                 [Florida, Lottery]            0.000   \n",
       "79                               [Canada, Lotto, Max]            0.500   \n",
       "\n",
       "    Sentiment_Kicker                            Keyword_Frequency_Title  \\\n",
       "0          -0.155556  {'to': 1, 'for': 0, 'in': 0, 'million': 0, 'up...   \n",
       "1           0.136364  {'to': 0, 'for': 0, 'in': 0, 'million': 0, 'up...   \n",
       "2           0.000000  {'to': 1, 'for': 0, 'in': 0, 'million': 0, 'up...   \n",
       "3          -0.375000  {'to': 1, 'for': 0, 'in': 0, 'million': 1, 'up...   \n",
       "4           0.000000  {'to': 0, 'for': 0, 'in': 0, 'million': 0, 'up...   \n",
       "..               ...                                                ...   \n",
       "75          0.000000  {'to': 0, 'for': 0, 'in': 1, 'million': 0, 'up...   \n",
       "76          0.000000  {'to': 0, 'for': 0, 'in': 0, 'million': 0, 'up...   \n",
       "77          0.300000  {'to': 0, 'for': 0, 'in': 0, 'million': 0, 'up...   \n",
       "78          0.136364  {'to': 1, 'for': 0, 'in': 0, 'million': 0, 'up...   \n",
       "79          0.000000  {'to': 0, 'for': 0, 'in': 0, 'million': 0, 'up...   \n",
       "\n",
       "                             Keyword_Frequency_Kicker  \\\n",
       "0   {'to': 2, 'for': 0, 'in': 1, 'million': 0, 'up...   \n",
       "1   {'to': 0, 'for': 0, 'in': 1, 'million': 0, 'up...   \n",
       "2   {'to': 0, 'for': 0, 'in': 0, 'million': 0, 'up...   \n",
       "3   {'to': 1, 'for': 0, 'in': 0, 'million': 1, 'up...   \n",
       "4   {'to': 1, 'for': 0, 'in': 1, 'million': 0, 'up...   \n",
       "..                                                ...   \n",
       "75  {'to': 0, 'for': 0, 'in': 0, 'million': 0, 'up...   \n",
       "76  {'to': 1, 'for': 0, 'in': 0, 'million': 0, 'up...   \n",
       "77  {'to': 0, 'for': 0, 'in': 0, 'million': 0, 'up...   \n",
       "78  {'to': 0, 'for': 0, 'in': 1, 'million': 1, 'up...   \n",
       "79  {'to': 0, 'for': 1, 'in': 0, 'million': 1, 'up...   \n",
       "\n",
       "    Readability_Score_Title  Readability_Score_Kicker  Title_Complexity  \n",
       "0                      0.00                  0.000000          6.000000  \n",
       "1                      0.00                  0.000000          3.750000  \n",
       "2                      0.00                  0.000000          6.000000  \n",
       "3                      0.00                 95.939286          4.833333  \n",
       "4                     49.48                  0.000000          6.800000  \n",
       "..                      ...                       ...               ...  \n",
       "75                     0.00                -18.500000          3.166667  \n",
       "76                     0.00                  0.000000          9.000000  \n",
       "77                     0.00                  0.000000          8.333333  \n",
       "78                     0.00                  0.000000          5.800000  \n",
       "79                     0.00                  0.000000          4.833333  \n",
       "\n",
       "[80 rows x 17 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "\n",
    "def extract_keywords(titles, num_keywords=10):\n",
    "    \"\"\"Extract the most frequent keywords from the titles.\"\"\"\n",
    "    # Combine all titles into a single string\n",
    "    combined_text = ' '.join(titles)\n",
    "\n",
    "    # Remove punctuation and convert to lowercase\n",
    "    combined_text = re.sub(r'[^\\w\\s]', '', combined_text).lower()\n",
    "\n",
    "    # Split the text into words\n",
    "    words = combined_text.split()\n",
    "\n",
    "    # Count the frequency of each word\n",
    "    word_counts = Counter(words)\n",
    "\n",
    "    # Get the most common keywords\n",
    "    common_keywords = word_counts.most_common(num_keywords)\n",
    "\n",
    "    return [keyword for keyword, count in common_keywords]\n",
    "\n",
    "def post_process_data(df):\n",
    "    \"\"\"Perform post-processing on the scraped data.\"\"\"\n",
    "\n",
    "    def calculate_readability(text):\n",
    "        \"\"\"Calculate readability score using Flesch-Kincaid readability tests.\"\"\"\n",
    "        words = text.split()\n",
    "        num_words = len(words)\n",
    "        num_sentences = text.count('.') + text.count('!') + text.count('?')\n",
    "        num_syllables = sum([len(re.findall(r'[aeiouy]+', word.lower())) for word in words])\n",
    "\n",
    "        if num_words == 0 or num_sentences == 0:\n",
    "            return 0\n",
    "\n",
    "        flesch_kincaid_score = 206.835 - 1.015 * (num_words / num_sentences) - 84.6 * (num_syllables / num_words)\n",
    "        return flesch_kincaid_score\n",
    "\n",
    "    def calculate_complexity(text):\n",
    "        \"\"\"Calculate title complexity based on average word length and sentence length.\"\"\"\n",
    "        words = text.split()\n",
    "        num_words = len(words)\n",
    "\n",
    "        if num_words == 0:\n",
    "            return 0\n",
    "\n",
    "        avg_word_length = sum(len(word) for word in words) / num_words\n",
    "        return avg_word_length\n",
    "\n",
    "    def sentiment_analysis(text):\n",
    "        \"\"\"Perform sentiment analysis on the text.\"\"\"\n",
    "        analysis = TextBlob(text)\n",
    "        return analysis.sentiment.polarity\n",
    "\n",
    "    # Extract keywords from all titles\n",
    "    keywords_to_check = extract_keywords(df['Title'])\n",
    "\n",
    "    def keyword_frequency(text, keywords):\n",
    "        \"\"\"Count frequency of specific keywords in the text.\"\"\"\n",
    "        word_list = text.lower().split()\n",
    "        keyword_count = {keyword: word_list.count(keyword) for keyword in keywords}\n",
    "        return keyword_count\n",
    "\n",
    "    # Word count in Title\n",
    "    df['Word_Count_Title'] = df['Title'].apply(lambda x: len(x.split()))\n",
    "\n",
    "    # Word count in Kicker\n",
    "    df['Word_Count_Kicker'] = df['Kicker'].apply(lambda x: len(x.split()))\n",
    "\n",
    "    # Character count in Title\n",
    "    df['Character_Count_Title'] = df['Title'].apply(lambda x: len(x))\n",
    "\n",
    "    # Character count in Kicker\n",
    "    df['Character_Count_Kicker'] = df['Kicker'].apply(lambda x: len(x))\n",
    "\n",
    "    # List of words that start with a capital letter in Title\n",
    "    df['Capital_Words_Kicker'] = df['Kicker'].apply(lambda x: [word for word in x.split() if word.istitle()])\n",
    "\n",
    "    # Sentiment analysis on Title\n",
    "    df['Sentiment_Title'] = df['Title'].apply(sentiment_analysis)\n",
    "\n",
    "    # Sentiment analysis on Kicker\n",
    "    df['Sentiment_Kicker'] = df['Kicker'].apply(sentiment_analysis)\n",
    "\n",
    "    # Keyword frequency count in Title\n",
    "    df['Keyword_Frequency_Title'] = df['Title'].apply(lambda x: keyword_frequency(x, keywords_to_check))\n",
    "\n",
    "    # Keyword frequency count in Kicker\n",
    "    df['Keyword_Frequency_Kicker'] = df['Kicker'].apply(lambda x: keyword_frequency(x, keywords_to_check))\n",
    "\n",
    "    # Readability Score of Title\n",
    "    df['Readability_Score_Title'] = df['Title'].apply(calculate_readability)\n",
    "\n",
    "    # Readability Score of Kicker\n",
    "    df['Readability_Score_Kicker'] = df['Kicker'].apply(calculate_readability)\n",
    "\n",
    "    # Title complexity based on average word length and sentence length\n",
    "    df['Title_Complexity'] = df['Title'].apply(calculate_complexity)\n",
    "\n",
    "    return df\n",
    "\n",
    "combined_df = post_process_data(combined_df)\n",
    "\n",
    "# Display the processed DataFrame\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\56937\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (4.29.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\56937\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (1.4.1)\n",
      "Requirement already satisfied: webdriver-manager in c:\\users\\56937\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (4.0.2)\n",
      "Requirement already satisfied: textblob in c:\\users\\56937\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.19.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in c:\\users\\56937\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (2.3.0)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\56937\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from selenium) (0.29.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\56937\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from selenium) (0.12.2)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\56937\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from selenium) (2025.1.31)\n",
      "Requirement already satisfied: typing_extensions~=4.9 in c:\\users\\56937\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from selenium) (4.12.2)\n",
      "Requirement already satisfied: websocket-client~=1.8 in c:\\users\\56937\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from selenium) (1.8.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\56937\\appdata\\roaming\\python\\python39\\site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\56937\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\56937\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas) (1.20.2)\n",
      "Requirement already satisfied: requests in c:\\users\\56937\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from webdriver-manager) (2.32.3)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\56937\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from webdriver-manager) (1.0.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\56937\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from webdriver-manager) (24.2)\n",
      "Requirement already satisfied: nltk>=3.9 in c:\\users\\56937\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from textblob) (3.9.1)\n",
      "Requirement already satisfied: click in c:\\users\\56937\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nltk>=3.9->textblob) (8.1.8)\n",
      "Requirement already satisfied: joblib in c:\\users\\56937\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nltk>=3.9->textblob) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\56937\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nltk>=3.9->textblob) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\56937\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nltk>=3.9->textblob) (4.67.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\56937\\appdata\\roaming\\python\\python39\\site-packages (from python-dateutil>=2.8.1->pandas) (1.15.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in c:\\users\\56937\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from trio~=0.17->selenium) (25.1.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\56937\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\56937\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from trio~=0.17->selenium) (3.10)\n",
      "Requirement already satisfied: outcome in c:\\users\\56937\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\56937\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from trio~=0.17->selenium) (1.3.1)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\56937\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from trio~=0.17->selenium) (1.17.1)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\56937\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from trio~=0.17->selenium) (1.2.2)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\56937\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\56937\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\56937\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->webdriver-manager) (3.4.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\56937\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.22)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\56937\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\56937\\appdata\\roaming\\python\\python39\\site-packages (from click->nltk>=3.9->textblob) (0.4.4)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-572df6b4453d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0murl\u001b[0m \u001b[1;32min\u001b[0m \u001b[0murls\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 136\u001b[1;33m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_news_details\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_pages\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    137\u001b[0m     \u001b[0mcombined_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcombined_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-572df6b4453d>\u001b[0m in \u001b[0;36mextract_news_details\u001b[1;34m(base_url, max_pages)\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[1;31m# Iterate over each element and extract the necessary details\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mitems\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m             \u001b[0mtitle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCLASS_NAME\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'fuente_roboto_slab'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m             \u001b[0mkicker\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTAG_NAME\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'a'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_attribute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'title'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m             \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTAG_NAME\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'img'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_attribute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'src'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\56937\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py\u001b[0m in \u001b[0;36mfind_element\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    599\u001b[0m         \"\"\"\n\u001b[0;32m    600\u001b[0m         \u001b[0mby\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlocator_converter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 601\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_execute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFIND_CHILD_ELEMENT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"using\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"value\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"value\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    602\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    603\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfind_elements\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mID\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mWebElement\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\56937\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py\u001b[0m in \u001b[0;36m_execute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    570\u001b[0m             \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"id\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfind_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mID\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mWebElement\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\56937\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    425\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"sessionId\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msession_id\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    426\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 427\u001b[1;33m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    428\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\56937\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\selenium\\webdriver\\remote\\remote_connection.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    402\u001b[0m         \u001b[0mtrimmed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_trim_large_entries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    403\u001b[0m         \u001b[0mLOGGER\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s %s %s\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcommand_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrimmed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 404\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    405\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    406\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\56937\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\selenium\\webdriver\\remote\\remote_connection.py\u001b[0m in \u001b[0;36m_request\u001b[1;34m(self, method, url, body)\u001b[0m\n\u001b[0;32m    426\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    427\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_client_config\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeep_alive\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 428\u001b[1;33m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_client_config\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    429\u001b[0m             \u001b[0mstatuscode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    430\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\56937\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\urllib3\\_request_methods.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, body, fields, headers, json, **urlopen_kw)\u001b[0m\n\u001b[0;32m    141\u001b[0m             )\n\u001b[0;32m    142\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 143\u001b[1;33m             return self.request_encode_body(\n\u001b[0m\u001b[0;32m    144\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfields\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfields\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0murlopen_kw\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m             )\n",
      "\u001b[1;32mc:\\Users\\56937\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\urllib3\\_request_methods.py\u001b[0m in \u001b[0;36mrequest_encode_body\u001b[1;34m(self, method, url, fields, headers, encode_multipart, multipart_boundary, **urlopen_kw)\u001b[0m\n\u001b[0;32m    276\u001b[0m         \u001b[0mextra_kw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murlopen_kw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 278\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mextra_kw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\56937\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\urllib3\\poolmanager.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, redirect, **kw)\u001b[0m\n\u001b[0;32m    441\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 443\u001b[1;33m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest_uri\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m         \u001b[0mredirect_location\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mredirect\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_redirect_location\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\56937\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    785\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    786\u001b[0m             \u001b[1;31m# Make the request on the HTTPConnection object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 787\u001b[1;33m             response = self._make_request(\n\u001b[0m\u001b[0;32m    788\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\56937\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    532\u001b[0m         \u001b[1;31m# Receive the response from the server\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 534\u001b[1;33m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    535\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mBaseSSLError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    536\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\56937\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36mgetresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    514\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    515\u001b[0m         \u001b[1;31m# Get the response from http.client.HTTPConnection\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 516\u001b[1;33m         \u001b[0mhttplib_response\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    517\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\56937\\AppData\\Local\\Programs\\Python\\Python39\\lib\\http\\client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1345\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1346\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1347\u001b[1;33m                 \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1348\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1349\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\56937\\AppData\\Local\\Programs\\Python\\Python39\\lib\\http\\client.py\u001b[0m in \u001b[0;36mbegin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    305\u001b[0m         \u001b[1;31m# read until we get a non-100 response\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 307\u001b[1;33m             \u001b[0mversion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\56937\\AppData\\Local\\Programs\\Python\\Python39\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    266\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 268\u001b[1;33m         \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"iso-8859-1\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    269\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"status line\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\56937\\AppData\\Local\\Programs\\Python\\Python39\\lib\\socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    702\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    703\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 704\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    705\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    706\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import re\n",
    "import os\n",
    "\n",
    "# Install necessary libraries\n",
    "!pip install selenium pandas webdriver-manager textblob\n",
    "\n",
    "def remove_date(text):\n",
    "    \"\"\"Remove date from the Title text.\"\"\"\n",
    "    return ' '.join(text.split()[1:])\n",
    "\n",
    "def extract_news_details(base_url, max_pages):\n",
    "    \"\"\"Extract news details from the given base URL up to the specified number of pages.\"\"\"\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument('--headless')\n",
    "    options.add_argument('--no-sandbox')\n",
    "    options.add_argument('--disable-dev-shm-usage')\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "\n",
    "    page_url = base_url\n",
    "\n",
    "    # Initialize lists to store the details\n",
    "    titles = []\n",
    "    kickers = []\n",
    "    images = []\n",
    "    links = []\n",
    "    dates = []\n",
    "\n",
    "    # Initialize page counter\n",
    "    page_counter = 0\n",
    "\n",
    "    while page_counter < max_pages:\n",
    "        # Open the URL\n",
    "        driver.get(page_url)\n",
    "\n",
    "        # Select all div elements with the class \"item_noticias\"\n",
    "        items = driver.find_elements(By.CLASS_NAME, 'item_noticias')\n",
    "\n",
    "        # Iterate over each element and extract the necessary details\n",
    "        for item in items:\n",
    "            title = item.find_element(By.CLASS_NAME, 'fuente_roboto_slab').text\n",
    "            kicker = item.find_element(By.TAG_NAME, 'a').get_attribute('title')\n",
    "            image = item.find_element(By.TAG_NAME, 'img').get_attribute('src')\n",
    "            link = item.find_element(By.TAG_NAME, 'a').get_attribute('href')\n",
    "            date = item.find_element(By.CLASS_NAME, 'fecha_item_listado_noticias').text\n",
    "\n",
    "            titles.append(title)\n",
    "            kickers.append(kicker)\n",
    "            images.append(image)\n",
    "            links.append(link)\n",
    "            dates.append(date)\n",
    "\n",
    "        # Check if there is a \"Next\" button to go to the next page\n",
    "        try:\n",
    "            next_button = driver.find_element(By.CLASS_NAME, 'boton_paginador siguiente')\n",
    "            page_number = int(page_url.split('=')[-1]) if '=' in page_url else 1\n",
    "            page_url = f\"{base_url}?buscar=&pagina={page_number + 1}\"\n",
    "            page_counter += 1\n",
    "        except:\n",
    "            break\n",
    "\n",
    "    # Close the WebDriver\n",
    "    driver.quit()\n",
    "\n",
    "    # Create a DataFrame to store the details\n",
    "    data = {\n",
    "        'Date': dates,\n",
    "        'Title': titles,\n",
    "        'Kicker': kickers,\n",
    "        'Image': images,\n",
    "        'Link': links\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Apply the remove_date function to the 'Title' column\n",
    "    df['Title'] = df['Title'].apply(remove_date)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_category_links():\n",
    "    \"\"\"Get category links from the main page.\"\"\"\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument('--headless')\n",
    "    options.add_argument('--no-sandbox')\n",
    "    options.add_argument('--disable-dev-shm-usage')\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "\n",
    "    url = \"https://www.yogonet.com/international/\"\n",
    "\n",
    "    # Open the URL\n",
    "    driver.get(url)\n",
    "\n",
    "    # Move cursor over the \"Categories\" tab\n",
    "    categories_tab = driver.find_element(By.CSS_SELECTOR, '.item_menu.transition_02.tiene_hijos.categorias')\n",
    "    ActionChains(driver).move_to_element(categories_tab).perform()\n",
    "\n",
    "    # Select all elements with the class \"item_menu hijo\"\n",
    "    items = driver.find_elements(By.CSS_SELECTOR, '.contenedor_items_hijos .item_menu.hijo')\n",
    "\n",
    "    # Initialize list to store the links\n",
    "    links = []\n",
    "\n",
    "    # Iterate over each element and extract the necessary details\n",
    "    for item in items:\n",
    "        link = item.find_element(By.CSS_SELECTOR, 'a').get_attribute('href')\n",
    "        links.append(link)\n",
    "\n",
    "    # Close the WebDriver\n",
    "    driver.quit()\n",
    "\n",
    "    # Create a DataFrame to store the details\n",
    "    data = {\n",
    "        'Link': links\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Convert the 'Link' column to a list of URLs\n",
    "    urls = df['Link'].tolist()\n",
    "\n",
    "    return urls[:4]\n",
    "\n",
    "\n",
    "# Call the function and display the list of URLs\n",
    "urls = get_category_links()\n",
    "\n",
    "# Initialize an empty DataFrame to store combined results\n",
    "combined_df = pd.DataFrame()\n",
    "\n",
    "for url in urls:\n",
    "    df = extract_news_details(url, max_pages=1)\n",
    "    combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
    "\n",
    "\n",
    "def extract_keywords(titles):\n",
    "    \"\"\"Extract the most frequent keywords from the titles.\"\"\"\n",
    "    # Combine all titles into a single string\n",
    "    combined_text = ' '.join(titles)\n",
    "\n",
    "    # Remove punctuation and convert to lowercase\n",
    "    combined_text = re.sub(r'[^\\w\\s]', '', combined_text).lower()\n",
    "\n",
    "    # Split the text into words\n",
    "    words = combined_text.split()\n",
    "\n",
    "    # Count the frequency of each word\n",
    "    word_counts = Counter(words)\n",
    "\n",
    "    # Find the maximum frequency\n",
    "    max_frequency = max(word_counts.values()) if word_counts else 0\n",
    "\n",
    "    # Get keywords with maximum frequency\n",
    "    keywords = [word for word, count in word_counts.items() if count == max_frequency]\n",
    "    \n",
    "    return keywords\n",
    "\n",
    "def post_process_data(df):\n",
    "    \"\"\"Perform post-processing on the scraped data.\"\"\"\n",
    "\n",
    "    def calculate_readability(text):\n",
    "        \"\"\"Calculate readability score using Flesch-Kincaid readability tests.\"\"\"\n",
    "        words = text.split()\n",
    "        num_words = len(words)\n",
    "        num_sentences = text.count('.') + text.count('!') + text.count('?')\n",
    "        num_syllables = sum([len(re.findall(r'[aeiouy]+', word.lower())) for word in words])\n",
    "\n",
    "        if num_words == 0 or num_sentences == 0:\n",
    "            return 0\n",
    "\n",
    "        flesch_kincaid_score = 206.835 - 1.015 * (num_words / num_sentences) - 84.6 * (num_syllables / num_words)\n",
    "        return flesch_kincaid_score\n",
    "\n",
    "    def calculate_complexity(text):\n",
    "        \"\"\"Calculate title complexity based on average word length and sentence length.\"\"\"\n",
    "        words = text.split()\n",
    "        num_words = len(words)\n",
    "\n",
    "        if num_words == 0:\n",
    "            return 0\n",
    "\n",
    "        avg_word_length = sum(len(word) for word in words) / num_words\n",
    "        return avg_word_length\n",
    "\n",
    "    def sentiment_analysis(text):\n",
    "        \"\"\"Perform sentiment analysis on the text.\"\"\"\n",
    "        analysis = TextBlob(text)\n",
    "        return analysis.sentiment.polarity\n",
    "\n",
    "    # Extract keywords from all titles\n",
    "    keywords_to_check = extract_keywords(df['Title'])\n",
    "\n",
    "    def keyword_frequency(text, keywords):\n",
    "        \"\"\"Count frequency of specific keywords in the text.\"\"\"\n",
    "        word_list = text.lower().split()\n",
    "        keyword_count = {keyword: word_list.count(keyword) for keyword in keywords}\n",
    "        return keyword_count\n",
    "\n",
    "    # Word count in Title\n",
    "    df['Word_Count_Title'] = df['Title'].apply(lambda x: len(x.split()))\n",
    "\n",
    "    # Word count in Kicker\n",
    "    df['Word_Count_Kicker'] = df['Kicker'].apply(lambda x: len(x.split()))\n",
    "\n",
    "    # Character count in Title\n",
    "    df['Character_Count_Title'] = df['Title'].apply(lambda x: len(x))\n",
    "\n",
    "    # Character count in Kicker\n",
    "    df['Character_Count_Kicker'] = df['Kicker'].apply(lambda x: len(x))\n",
    "\n",
    "    # List of words that start with a capital letter in Title\n",
    "    df['Capital_Words_Kicker'] = df['Kicker'].apply(lambda x: [word for word in x.split() if word.istitle()])\n",
    "\n",
    "    # Sentiment analysis on Title\n",
    "    df['Sentiment_Title'] = df['Title'].apply(sentiment_analysis)\n",
    "\n",
    "    # Sentiment analysis on Kicker\n",
    "    df['Sentiment_Kicker'] = df['Kicker'].apply(sentiment_analysis)\n",
    "\n",
    "    # Keyword frequency count in Title\n",
    "    df['Keyword_Frequency_Title'] = df['Title'].apply(lambda x: keyword_frequency(x, keywords_to_check))\n",
    "\n",
    "    # Keyword frequency count in Kicker\n",
    "    df['Keyword_Frequency_Kicker'] = df['Kicker'].apply(lambda x: keyword_frequency(x, keywords_to_check))\n",
    "\n",
    "    # Readability Score of Title\n",
    "    df['Readability_Score_Title'] = df['Title'].apply(calculate_readability)\n",
    "\n",
    "    # Readability Score of Kicker\n",
    "    df['Readability_Score_Kicker'] = df['Kicker'].apply(calculate_readability)\n",
    "\n",
    "    # Title complexity based on average word length and sentence length\n",
    "    df['Title_Complexity'] = df['Title'].apply(calculate_complexity)\n",
    "\n",
    "    return df\n",
    "\n",
    "combined_df = post_process_data(combined_df)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "combined_df.to_csv('combined_news_data.csv', encoding='utf-8-sig', index=False)\n",
    "\n",
    "# Save the DataFrame to a CSV file in the current directory\n",
    "current_directory = os.getcwd()\n",
    "file_path = os.path.join(current_directory, 'combined_news_data.csv')\n",
    "combined_df.to_csv(file_path, encoding='utf-8-sig', index=False)\n",
    "\n",
    "print(f\"File saved to: {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved to: c:\\Users\\56937\\OneDrive\\data_engineer\\scraper_news_yogonet\\combined_news_data.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.by import By\n",
    "from textblob import TextBlob\n",
    "\n",
    "def remove_date(text):\n",
    "    \"\"\"Remove date from the Title text.\"\"\"\n",
    "    return ' '.join(text.split()[1:])\n",
    "\n",
    "def extract_news_details(base_url, max_pages):\n",
    "    \"\"\"Extract news details from the given base URL up to the specified number of pages.\"\"\"\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument('--headless')\n",
    "    options.add_argument('--no-sandbox')\n",
    "    options.add_argument('--disable-dev-shm-usage')\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "\n",
    "    page_url = base_url\n",
    "\n",
    "    # Initialize lists to store the details\n",
    "    titles, kickers, images, links, dates = [], [], [], [], []\n",
    "\n",
    "    # Initialize page counter\n",
    "    page_counter = 0\n",
    "\n",
    "    while page_counter < max_pages:\n",
    "        # Open the URL\n",
    "        driver.get(page_url)\n",
    "\n",
    "        # Select all div elements with the class \"item_noticias\"\n",
    "        items = driver.find_elements(By.CLASS_NAME, 'item_noticias')\n",
    "\n",
    "        # Iterate over each element and extract the necessary details\n",
    "        for item in items:\n",
    "            title = item.find_element(By.CLASS_NAME, 'fuente_roboto_slab').text\n",
    "            kicker = item.find_element(By.TAG_NAME, 'a').get_attribute('title')\n",
    "            image = item.find_element(By.TAG_NAME, 'img').get_attribute('src')\n",
    "            link = item.find_element(By.TAG_NAME, 'a').get_attribute('href')\n",
    "            date = item.find_element(By.CLASS_NAME, 'fecha_item_listado_noticias').text\n",
    "\n",
    "            titles.append(title)\n",
    "            kickers.append(kicker)\n",
    "            images.append(image)\n",
    "            links.append(link)\n",
    "            dates.append(date)\n",
    "\n",
    "        # Check if there is a \"Next\" button to go to the next page\n",
    "        try:\n",
    "            next_button = driver.find_element(By.CLASS_NAME, 'boton_paginador siguiente')\n",
    "            page_number = int(page_url.split('=')[-1]) if '=' in page_url else 1\n",
    "            page_url = f\"{base_url}?buscar=&pagina={page_number + 1}\"\n",
    "            page_counter += 1\n",
    "        except:\n",
    "            break\n",
    "\n",
    "    # Close the WebDriver\n",
    "    driver.quit()\n",
    "\n",
    "    # Create a DataFrame to store the details\n",
    "    data = {\n",
    "        'Date': dates,\n",
    "        'Title': titles,\n",
    "        'Kicker': kickers,\n",
    "        'Image': images,\n",
    "        'Link': links\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Apply the remove_date function to the 'Title' column\n",
    "    df['Title'] = df['Title'].apply(remove_date)\n",
    "\n",
    "    return df\n",
    "\n",
    "def get_category_links():\n",
    "    \"\"\"Get category links from the main page.\"\"\"\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument('--headless')\n",
    "    options.add_argument('--no-sandbox')\n",
    "    options.add_argument('--disable-dev-shm-usage')\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "\n",
    "    url = \"https://www.yogonet.com/international/\"\n",
    "\n",
    "    # Open the URL\n",
    "    driver.get(url)\n",
    "\n",
    "    # Move cursor over the \"Categories\" tab\n",
    "    categories_tab = driver.find_element(By.CSS_SELECTOR, '.item_menu.transition_02.tiene_hijos.categorias')\n",
    "    ActionChains(driver).move_to_element(categories_tab).perform()\n",
    "\n",
    "    # Select all elements with the class \"item_menu hijo\"\n",
    "    items = driver.find_elements(By.CSS_SELECTOR, '.contenedor_items_hijos .item_menu.hijo')\n",
    "\n",
    "    # Initialize list to store the links\n",
    "    links = [item.find_element(By.CSS_SELECTOR, 'a').get_attribute('href') for item in items]\n",
    "\n",
    "    # Close the WebDriver\n",
    "    driver.quit()\n",
    "\n",
    "    return links[:4]\n",
    "\n",
    "def extract_keywords(text, num_keywords=10):\n",
    "    \"\"\"Extract the most frequent keywords from a given text.\"\"\"\n",
    "    combined_text = re.sub(r'[^\\w\\s]', '', text).lower()\n",
    "    \n",
    "    words = combined_text.split()\n",
    "    \n",
    "    word_counts = Counter(words)\n",
    "    \n",
    "    common_keywords = word_counts.most_common(num_keywords)\n",
    "    \n",
    "    return [keyword for keyword, count in common_keywords]\n",
    "\n",
    "def post_process_data(df):\n",
    "    \"\"\"Perform post-processing on the scraped data.\"\"\"\n",
    "\n",
    "    def calculate_readability(text):\n",
    "        \"\"\"Calculate readability score using Flesch-Kincaid readability tests.\"\"\"\n",
    "        words = text.split()\n",
    "        num_words = len(words)\n",
    "        num_sentences = text.count('.') + text.count('!') + text.count('?')\n",
    "        num_syllables = sum([len(re.findall(r'[aeiouy]+', word.lower())) for word in words])\n",
    "\n",
    "        if num_words == 0 or num_sentences == 0:\n",
    "            return 0\n",
    "\n",
    "        flesch_kincaid_score = 206.835 - 1.015 * (num_words / num_sentences) - 84.6 * (num_syllables / num_words)\n",
    "        return flesch_kincaid_score\n",
    "\n",
    "    def calculate_complexity(text):\n",
    "        \"\"\"Calculate title complexity based on average word length and sentence length.\"\"\"\n",
    "        words = text.split()\n",
    "        num_words = len(words)\n",
    "\n",
    "        if num_words == 0:\n",
    "            return 0\n",
    "\n",
    "        avg_word_length = sum(len(word) for word in words) / num_words\n",
    "        return avg_word_length\n",
    "\n",
    "    def sentiment_analysis(text):\n",
    "        \"\"\"Perform sentiment analysis on the text.\"\"\"\n",
    "        analysis = TextBlob(text)\n",
    "        return analysis.sentiment.polarity\n",
    "\n",
    "    # Extract keywords from all titles (maximum 10)\n",
    "    keywords_to_check_title = extract_keywords(' '.join(df['Title']))\n",
    "    keywords_to_check_kicker = extract_keywords(' '.join(df['Kicker']))\n",
    "\n",
    "    def keyword_frequency(text, keywords):\n",
    "        \"\"\"Count frequency of specific keywords in the text.\"\"\"\n",
    "        word_list = text.lower().split()\n",
    "        keyword_count = {keyword: word_list.count(keyword) for keyword in keywords}\n",
    "        return keyword_count\n",
    "\n",
    "    # Word count in Title\n",
    "    df['Word_Count_Title'] = df['Title'].apply(lambda x: len(x.split()))\n",
    "\n",
    "    # Word count in Kicker\n",
    "    df['Word_Count_Kicker'] = df['Kicker'].apply(lambda x: len(x.split()))\n",
    "\n",
    "    # Character count in Title\n",
    "    df['Character_Count_Title'] = df['Title'].apply(lambda x: len(x))\n",
    "\n",
    "    # Character count in Kicker\n",
    "    df['Character_Count_Kicker'] = df['Kicker'].apply(lambda x: len(x))\n",
    "\n",
    "    # List of words that start with a capital letter in Title\n",
    "    df['Capital_Words_Kicker'] = df['Kicker'].apply(lambda x: [word for word in x.split() if word.istitle()])\n",
    "\n",
    "    # Sentiment analysis on Title\n",
    "    df['Sentiment_Title'] = df['Title'].apply(sentiment_analysis)\n",
    "\n",
    "    # Sentiment analysis on Kicker\n",
    "    df['Sentiment_Kicker'] = df['Kicker'].apply(sentiment_analysis)\n",
    "\n",
    "    # Keyword frequency count in Title\n",
    "    df['Keyword_Frequency_Title'] = df['Title'].apply(lambda x: keyword_frequency(x, keywords_to_check_title))\n",
    "\n",
    "    # Keyword frequency count in Kicker\n",
    "    df['Keyword_Frequency_Kicker'] = df['Kicker'].apply(lambda x: keyword_frequency(x, keywords_to_check_kicker))\n",
    "\n",
    "    # Readability Score of Title\n",
    "    df['Readability_Score_Title'] = df['Title'].apply(calculate_readability)\n",
    "\n",
    "    # Readability Score of Kicker\n",
    "    df['Readability_Score_Kicker'] = df['Kicker'].apply(calculate_readability)\n",
    "\n",
    "    # Title complexity based on average word length and sentence length\n",
    "    df['Title_Complexity'] = df['Title'].apply(calculate_complexity)\n",
    "\n",
    "    return df\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to run the pipeline.\"\"\"\n",
    "    # Call the function and display the list of URLs\n",
    "    urls = get_category_links()\n",
    "\n",
    "    # Initialize an empty DataFrame to store combined results\n",
    "    combined_df = pd.DataFrame()\n",
    "\n",
    "    for url in urls:\n",
    "        df = extract_news_details(url, max_pages=1)\n",
    "        combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
    "\n",
    "    combined_df = post_process_data(combined_df)\n",
    "\n",
    "    # Save the DataFrame to a CSV file\n",
    "    file_path = os.path.join(os.getcwd(), 'combined_news_data.csv')\n",
    "    combined_df.to_csv(file_path, encoding='utf-8-sig', index=False)\n",
    "\n",
    "    print(f\"File saved to: {file_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
